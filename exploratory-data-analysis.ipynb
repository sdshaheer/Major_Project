{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport cv2\nimport matplotlib.image as mpimg\n\nimport os\nimport PIL\nimport PIL.Image\nimport pathlib\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-23T10:12:27.28849Z","iopub.execute_input":"2023-01-23T10:12:27.289262Z","iopub.status.idle":"2023-01-23T10:12:27.622965Z","shell.execute_reply.started":"2023-01-23T10:12:27.289136Z","shell.execute_reply":"2023-01-23T10:12:27.621791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Extraction","metadata":{}},{"cell_type":"code","source":"DATASET_PATH = '/kaggle/input/fashion-product-images-dataset/fashion-dataset/fashion-dataset'\n\nprint(os.listdir(DATASET_PATH))","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:16:59.027342Z","iopub.execute_input":"2023-01-23T10:16:59.027765Z","iopub.status.idle":"2023-01-23T10:16:59.036058Z","shell.execute_reply.started":"2023-01-23T10:16:59.027727Z","shell.execute_reply":"2023-01-23T10:16:59.034746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset contains the following files:\n\n- **images.csv**: A CSV file containing the image filename and the link the image from which it is scrapped.\n- **images**: A folder that contains all the images listed in the CSV file.\n- **styles.csv**: A CSV file containing the textual details of each image like product name, colour, etc.\n- **styles**: A folder containing JSON files for each product that stores style attributes of each product seperately.","metadata":{}},{"cell_type":"markdown","source":"## Dataset Exploration (Exploratory Data Analysis)","metadata":{}},{"cell_type":"code","source":"styles_csv = pd.read_csv(os.path.join(DATASET_PATH, \"styles.csv\"), error_bad_lines=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:17:10.969095Z","iopub.execute_input":"2023-01-23T10:17:10.969532Z","iopub.status.idle":"2023-01-23T10:17:11.14656Z","shell.execute_reply.started":"2023-01-23T10:17:10.9695Z","shell.execute_reply":"2023-01-23T10:17:11.145194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"styles_csv.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:17:50.289421Z","iopub.execute_input":"2023-01-23T10:17:50.289892Z","iopub.status.idle":"2023-01-23T10:17:50.324245Z","shell.execute_reply.started":"2023-01-23T10:17:50.289837Z","shell.execute_reply":"2023-01-23T10:17:50.322316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that few lines were skipped while reading this CSV. The warning prompt isn't quite intuitive. We can see the count of skipped lines later.","metadata":{}},{"cell_type":"code","source":"images_csv = pd.read_csv(os.path.join(DATASET_PATH, \"images.csv\"), error_bad_lines=False)\nstyles_csv.shape, images_csv.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:17:58.241365Z","iopub.execute_input":"2023-01-23T10:17:58.24196Z","iopub.status.idle":"2023-01-23T10:17:58.450819Z","shell.execute_reply.started":"2023-01-23T10:17:58.241916Z","shell.execute_reply":"2023-01-23T10:17:58.449626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ideally we should have same rows in both images and styles, but we have *44424* rows in styles_csv and *44446* rows in images_csv. This explains that around *22* rows were skipped while reading styles_csv.\n\nWe can skip those images that doesn't textual information while recommending based on text.","metadata":{}},{"cell_type":"code","source":"styles_csv.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T07:54:32.869162Z","iopub.execute_input":"2023-01-22T07:54:32.869947Z","iopub.status.idle":"2023-01-22T07:54:32.891059Z","shell.execute_reply.started":"2023-01-22T07:54:32.869909Z","shell.execute_reply":"2023-01-22T07:54:32.890153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that styles_csv contains all the textual information required to define a product. It has gender data, various categories, colour, display name, etc.\n\n","metadata":{}},{"cell_type":"code","source":"images_csv.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T07:54:32.89232Z","iopub.execute_input":"2023-01-22T07:54:32.892693Z","iopub.status.idle":"2023-01-22T07:54:32.90238Z","shell.execute_reply.started":"2023-01-22T07:54:32.892658Z","shell.execute_reply":"2023-01-22T07:54:32.901284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Textual EDA\n\nWe'll now explore the textual information from styles.csv.","metadata":{}},{"cell_type":"markdown","source":"### Gender Distribution","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\n\n# fig = px.colors.sequential.swatches_continuous()\n# fig.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:20:18.447527Z","iopub.execute_input":"2023-01-23T10:20:18.448016Z","iopub.status.idle":"2023-01-23T10:20:18.455199Z","shell.execute_reply.started":"2023-01-23T10:20:18.447978Z","shell.execute_reply":"2023-01-23T10:20:18.453617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.pie(styles_csv, styles_csv['gender'],color_discrete_sequence=px.colors.sequential.dense, opacity=0.9)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:18:51.998887Z","iopub.execute_input":"2023-01-23T10:18:51.999327Z","iopub.status.idle":"2023-01-23T10:18:53.669621Z","shell.execute_reply.started":"2023-01-23T10:18:51.999291Z","shell.execute_reply":"2023-01-23T10:18:53.668576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Master Category Distribution\n\n\nThis feature tells us about the primary category that the product belongs to (Apparel, Accessories, Footwear, etc.)","metadata":{}},{"cell_type":"code","source":"import plotly.graph_objects as go\n\ncatcounts = pd.value_counts(styles_csv['masterCategory'])\nfig = go.Figure([go.Bar(x=catcounts.index, y=catcounts.values ,text=catcounts.values, marker_color=px.colors.sequential.Aggrnyl)])\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T07:54:37.00462Z","iopub.execute_input":"2023-01-22T07:54:37.005017Z","iopub.status.idle":"2023-01-22T07:54:37.03101Z","shell.execute_reply.started":"2023-01-22T07:54:37.004979Z","shell.execute_reply":"2023-01-22T07:54:37.030153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sub Category Distribution","metadata":{}},{"cell_type":"code","source":"catcounts=pd.value_counts(styles_csv['subCategory'])\nfig = go.Figure([go.Bar(x=catcounts.index, y=catcounts.values ,text=catcounts.values, marker_color=px.colors.sequential.Aggrnyl)])\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T07:54:37.035205Z","iopub.execute_input":"2023-01-22T07:54:37.035826Z","iopub.status.idle":"2023-01-22T07:54:37.053984Z","shell.execute_reply.started":"2023-01-22T07:54:37.03579Z","shell.execute_reply":"2023-01-22T07:54:37.053147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Article Type Distribution","metadata":{}},{"cell_type":"code","source":"catcounts=pd.value_counts(styles_csv['articleType'])\nfig = go.Figure([go.Bar(x=catcounts.index, y=catcounts.values ,text=catcounts.values, marker_color=px.colors.sequential.Aggrnyl)])\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T07:54:37.055419Z","iopub.execute_input":"2023-01-22T07:54:37.055747Z","iopub.status.idle":"2023-01-22T07:54:37.069547Z","shell.execute_reply.started":"2023-01-22T07:54:37.055715Z","shell.execute_reply":"2023-01-22T07:54:37.068486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Season Distribution","metadata":{}},{"cell_type":"code","source":"seasons=pd.value_counts(styles_csv['season'])\n\nfig = go.Figure(data=[go.Scatter(\n    x=seasons.index, y=seasons.values,\n    mode='markers',\n    marker=dict(\n        color=px.colors.sequential.Aggrnyl,\n        opacity=[1, 0.8, 0.6, 0.4],\n        size=[40, 60, 80, 100])\n)]\n               )\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T07:54:37.071457Z","iopub.execute_input":"2023-01-22T07:54:37.071706Z","iopub.status.idle":"2023-01-22T07:54:37.096843Z","shell.execute_reply.started":"2023-01-22T07:54:37.071683Z","shell.execute_reply":"2023-01-22T07:54:37.096286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Usage Distribution","metadata":{}},{"cell_type":"code","source":"catcounts=pd.value_counts(styles_csv['usage'])\nfig = go.Figure([go.Bar(x=catcounts.index, y=catcounts.values ,text=catcounts.values, marker_color=px.colors.sequential.Aggrnyl)])\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T07:54:37.098028Z","iopub.execute_input":"2023-01-22T07:54:37.098367Z","iopub.status.idle":"2023-01-22T07:54:37.112125Z","shell.execute_reply.started":"2023-01-22T07:54:37.098335Z","shell.execute_reply":"2023-01-22T07:54:37.111227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Base Colour Distribution","metadata":{}},{"cell_type":"code","source":"catcounts=pd.value_counts(styles_csv['baseColour'])\nfig = go.Figure([go.Bar(x=catcounts.index, y=catcounts.values ,text=catcounts.values, marker_color=px.colors.sequential.Aggrnyl)])\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T07:54:37.113546Z","iopub.execute_input":"2023-01-22T07:54:37.114135Z","iopub.status.idle":"2023-01-22T07:54:37.130839Z","shell.execute_reply.started":"2023-01-22T07:54:37.114101Z","shell.execute_reply":"2023-01-22T07:54:37.130114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image EDA\n\nWe'll now explore the image data.","metadata":{}},{"cell_type":"code","source":"data_dir = pathlib.Path(DATASET_PATH).with_suffix('')\nimages = list(data_dir.glob('*/*.jpg'))","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:23:55.86552Z","iopub.execute_input":"2023-01-23T10:23:55.866022Z","iopub.status.idle":"2023-01-23T10:23:57.225707Z","shell.execute_reply.started":"2023-01-23T10:23:55.865985Z","shell.execute_reply":"2023-01-23T10:23:57.224682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PIL.Image.open(str(images[0]))","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:24:16.475903Z","iopub.execute_input":"2023-01-23T10:24:16.476569Z","iopub.status.idle":"2023-01-23T10:24:16.870475Z","shell.execute_reply.started":"2023-01-23T10:24:16.476512Z","shell.execute_reply":"2023-01-23T10:24:16.869218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PIL.Image.open(str(images[1]))","metadata":{"execution":{"iopub.status.busy":"2023-01-22T07:54:38.773251Z","iopub.execute_input":"2023-01-22T07:54:38.774162Z","iopub.status.idle":"2023-01-22T07:54:39.701527Z","shell.execute_reply.started":"2023-01-22T07:54:38.774125Z","shell.execute_reply":"2023-01-22T07:54:39.700316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll now modify the styles_csv to contain the image path column.","metadata":{}},{"cell_type":"code","source":"styles_csv['image'] = styles_csv.apply(lambda row: os.path.join(DATASET_PATH, 'images', str(row['id']) + \".jpg\"), axis=1)\nstyles_csv.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:25:38.682211Z","iopub.execute_input":"2023-01-23T10:25:38.683134Z","iopub.status.idle":"2023-01-23T10:25:39.377607Z","shell.execute_reply.started":"2023-01-23T10:25:38.683049Z","shell.execute_reply":"2023-01-23T10:25:39.375693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll look at few sample images for each category.","metadata":{}},{"cell_type":"code","source":"def load_image(img_path, resized_fac = 0.1):\n    img_object = plt.imread(img_path)\n    w, h, c = img_object.shape\n    resized = cv2.resize(img_object, (int(h*resized_fac), int(w*resized_fac)))\n    return resized","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:25:36.102156Z","iopub.execute_input":"2023-01-23T10:25:36.102673Z","iopub.status.idle":"2023-01-23T10:25:36.110048Z","shell.execute_reply.started":"2023-01-23T10:25:36.102619Z","shell.execute_reply":"2023-01-23T10:25:36.10882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_grid(image_list, group):\n    fig = plt.figure(figsize=(40, 10), facecolor=\"#e1ddbf\")\n    plt.suptitle(group, fontsize=40)\n    \n    samples = len(image_list)\n    \n    for i in range(samples):\n        ax = plt.subplot(1, 4, i + 1)\n        plt.imshow(load_image(image_list[i][0]))\n        plt.title(image_list[i][1], fontsize=8)\n        plt.axis(\"off\")\n    plt.show()  ","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:28:06.945878Z","iopub.execute_input":"2023-01-23T10:28:06.946758Z","iopub.status.idle":"2023-01-23T10:28:06.955317Z","shell.execute_reply.started":"2023-01-23T10:28:06.94671Z","shell.execute_reply":"2023-01-23T10:28:06.953963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_grouped_images(dataframe, column, samples=4):\n    groups = dataframe[column].unique()\n    grouped_dataframe = dataframe.groupby(column)\n    \n    for group in groups:\n        \n        try:\n            image_list = grouped_dataframe.get_group(group).sample(samples)[['image', 'productDisplayName']].values\n            plot_grid(image_list, group)\n        except:\n            image_list = grouped_dataframe.get_group(group).sample(1)[['image', 'productDisplayName']].values\n            plot_grid(image_list, group) ","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:28:07.063511Z","iopub.execute_input":"2023-01-23T10:28:07.064608Z","iopub.status.idle":"2023-01-23T10:28:07.072411Z","shell.execute_reply.started":"2023-01-23T10:28:07.064563Z","shell.execute_reply":"2023-01-23T10:28:07.07078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_grouped_images(styles_csv, 'masterCategory')","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:28:07.45485Z","iopub.execute_input":"2023-01-23T10:28:07.455378Z","iopub.status.idle":"2023-01-23T10:28:11.651997Z","shell.execute_reply.started":"2023-01-23T10:28:07.455337Z","shell.execute_reply":"2023-01-23T10:28:11.650656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_grouped_images(styles_csv, 'subCategory')","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:28:47.38074Z","iopub.execute_input":"2023-01-23T10:28:47.381477Z","iopub.status.idle":"2023-01-23T10:29:16.558307Z","shell.execute_reply.started":"2023-01-23T10:28:47.381438Z","shell.execute_reply":"2023-01-23T10:29:16.556592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}