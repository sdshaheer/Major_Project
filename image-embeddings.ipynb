{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom tensorflow.keras.layers import GlobalMaxPooling2D\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport cv2\nimport matplotlib.image as mpimg\n\nimport os\nimport PIL\nimport PIL.Image\nimport pathlib\n\nfrom tqdm import tqdm\nfrom tqdm._tqdm_notebook import tqdm_notebook\ntqdm_notebook.pandas()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# File wise constants\n\n\nIMAGE_WIDTH = 224\nIMAGE_HEIGHT = 224","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading data","metadata":{}},{"cell_type":"code","source":"DATASET_PATH = '/kaggle/input'\n\nprint(os.listdir(DATASET_PATH))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"styles_csv = pd.read_csv(os.path.join(DATASET_PATH, 'styles-image-path', 'styles_image_paths.csv'))\nstyles_csv.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using pretrained ResNet-50 model for recommendations","metadata":{}},{"cell_type":"code","source":"feature_extractor = ResNet50(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3)\n) # pretrained model\n\n\nfeature_extractor.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recommendation_model = keras.Sequential([\n    feature_extractor,\n    GlobalMaxPooling2D()\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recommendation_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# utility function to get embeddings for a single image\n\ndef get_single_image_embeddings(model, image_path):\n    image_object = image.load_img(image_path, target_size=(IMAGE_HEIGHT, IMAGE_WIDTH))\n    image_array = image.img_to_array(image_object)\n    image_array = np.expand_dims(image_array, axis=0)\n    image_array = preprocess_input(image_array)\n    \n    return model.predict(image_array).reshape(-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_list = os.listdir(os.path.join(DATASET_PATH, 'fashion-product-images-dataset', 'fashion-dataset', 'images'))\nstyles_list = [i.split('/')[-1] for i in styles_csv['image'].values]\nmissing_images = list(set(styles_list) - set(images_list))\nprint(missing_images)\n\nstyles_csv_ids = [int(i.split('.')[0]) for i in missing_images]\nprint(styles_csv_ids)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"styles_csv = styles_csv[~styles_csv['id'].isin(styles_csv_ids)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting an embedding for an image\n\nembedding = get_single_image_embeddings(recommendation_model, styles_csv.iloc[0].image)\nembedding.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_all_image_embeddings(model, dataframe):\n    try:\n        embeddings = dataframe['image'].progress_apply(lambda image_path: get_single_image_embeddings(model, image_path))\n    except Exception as e:\n        print(e)\n        pass\n    return embeddings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings = get_all_image_embeddings(recom)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numRows = embeddings.shape[0]\nnumCols = 2048\nemb_matrix = pd.DataFrame(index=range(numRows),columns=range(numCols))\nindexes = embeddings.index.values\nfor r in indexes:\n    emb_matrix.loc[r,:] = embeddings[r]\nemb_matrix.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# emb_matrix.columns = emb_matrix.columns.astype(str)\n# emb_matrix.to_feather(\"emb_matrix.feather\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# emb = pd.read_feather(\"/kaggle/working/emb_matrix.feather\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}